#!/usr/bin/env python3
"""
–£—Ç–∏–ª–∏—Ç–∞ –¥–ª—è –ø–µ—Ä–µ—Å—á–µ—Ç–∞ match_score –≤ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –∑–∞–ø–∏—Å—è—Ö lsd_stocks
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º v5.3 —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —à—Ç—Ä–∞—Ñ–∞ –∑–∞ –Ω–µ–∑–∞–ø—Ä–æ—à–µ–Ω–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É
"""

import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..'))

# –ó–∞–≥—Ä—É–∂–∞–µ–º .env –ü–ï–†–ï–î –∏–º–ø–æ—Ä—Ç–æ–º settings
from dotenv import load_dotenv
load_dotenv()

import asyncio
import logging
from decimal import Decimal
from sqlalchemy import select, update
from shared.database import get_async_session
from shared.database.models import LSDStock, OrderItem
from shared.utils.text_normalizer import normalize_product_name
from shared.utils.text_processing import normalize_and_extract_keywords, detect_processing_modifiers

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ============= –ö–û–ü–ò–Ø –ê–õ–ì–û–†–ò–¢–ú–ê v5.3 =============

def levenshtein_distance(s1: str, s2: str) -> int:
    """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è –õ–µ–≤–µ–Ω—à—Ç–µ–π–Ω–∞ –º–µ–∂–¥—É –¥–≤—É–º—è —Å—Ç—Ä–æ–∫–∞–º–∏"""
    if len(s1) < len(s2):
        return levenshtein_distance(s2, s1)
    
    if len(s2) == 0:
        return len(s1)
    
    previous_row = list(range(len(s2) + 1))
    for i, c1 in enumerate(s1):
        current_row = [i + 1]
        for j, c2 in enumerate(s2):
            insertions = previous_row[j + 1] + 1
            deletions = current_row[j] + 1
            substitutions = previous_row[j] + (c1 != c2)
            current_row.append(min(insertions, deletions, substitutions))
        previous_row = current_row
    
    return previous_row[-1]

def fuzzy_word_similarity(word1: str, word2: str) -> float:
    """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –Ω–µ—á—ë—Ç–∫–æ–π —Å—Ö–æ–∂–µ—Å—Ç–∏ –º–µ–∂–¥—É —Å–ª–æ–≤–∞–º–∏ (0.0 - 1.0)"""
    if word1 == word2:
        return 1.0
    
    # –ï—Å–ª–∏ –æ–¥–Ω–æ —Å–ª–æ–≤–æ —Å–æ–¥–µ—Ä–∂–∏—Ç—Å—è –≤ –¥—Ä—É–≥–æ–º
    if word1 in word2 or word2 in word1:
        shorter = min(len(word1), len(word2))
        longer = max(len(word1), len(word2))
        return shorter / longer * 0.9
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –õ–µ–≤–µ–Ω—à—Ç–µ–π–Ω–∞
    max_len = max(len(word1), len(word2))
    if max_len == 0:
        return 1.0
    
    distance = levenshtein_distance(word1, word2)
    similarity = 1.0 - (distance / max_len)
    
    return similarity if similarity >= 0.7 else 0.0

def calculate_match_score_v53(search_query: str, found_name: str, verbose: bool = False) -> tuple[float, bool]:
    """–ê–ª–≥–æ—Ä–∏—Ç–º match_score v5.3 —Å —à—Ç—Ä–∞—Ñ–æ–º –∑–∞ –Ω–µ–∑–∞–ø—Ä–æ—à–µ–Ω–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –ø—Ä–æ–¥—É–∫—Ç–æ–≤"""
    if not search_query or not found_name:
        return 0.0, False
    
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤
    normalized_search_query = normalize_product_name(search_query)
    normalized_found_name = normalize_product_name(found_name)
    
    search_words = normalize_and_extract_keywords(normalized_search_query)
    found_words = normalize_and_extract_keywords(normalized_found_name)
    
    if verbose:
        logger.debug(f"  Search words: {search_words}")
        logger.debug(f"  Found words: {found_words}")
    
    if not search_words:
        return 0.3, False
    
    if set(search_words) == set(found_words):
        return 1.0, True
    
    # –ü–æ–¥—Å—á—ë—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
    total_search_words = len(search_words)
    total_found_words = len(found_words)
    match_score = 0.0
    exact_matches = 0
    fuzzy_matches = 0
    
    for search_word in search_words:
        best_match_score = 0.0
        found_exact = False
        
        for found_word in found_words:
            similarity = fuzzy_word_similarity(search_word, found_word)
            
            if similarity == 1.0:
                best_match_score = 1.0
                found_exact = True
                break
            elif similarity >= 0.95:
                best_match_score = max(best_match_score, 0.95)
            elif similarity >= 0.7:
                best_match_score = max(best_match_score, similarity * 0.8)
        
        if found_exact:
            exact_matches += 1
            match_score += 1.0
        elif best_match_score >= 0.7:
            fuzzy_matches += 1
            match_score += best_match_score
    
    base_score = match_score / total_search_words
    bonus = 0.0
    penalty = 0.0
    
    has_full_coverage = (exact_matches + fuzzy_matches) >= total_search_words
    
    # –®—Ç—Ä–∞—Ñ –∑–∞ –¥–ª–∏–Ω—É
    word_count_ratio = total_found_words / total_search_words
    if word_count_ratio > 2.0:
        length_penalty = min(0.3, (word_count_ratio - 2.0) * 0.1)
        penalty += length_penalty
        if verbose:
            logger.debug(f"  ‚ö†Ô∏è Length penalty: -{length_penalty:.2f}")
    
    # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π —à—Ç—Ä–∞—Ñ –∑–∞ –Ω–µ—Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–µ—Ä–≤–æ–≥–æ —Å–ª–æ–≤–∞
    if search_words and found_words:
        first_search_word = search_words[0]
        first_found_word = found_words[0]
        
        first_word_similarity = fuzzy_word_similarity(first_search_word, first_found_word)
        
        if first_word_similarity < 0.7:
            found_in_top3 = False
            top3_position = -1
            for i, found_word in enumerate(found_words[:3]):
                if fuzzy_word_similarity(first_search_word, found_word) >= 0.8:
                    found_in_top3 = True
                    top3_position = i
                    break
            
            if not found_in_top3:
                if has_full_coverage:
                    first_word_mismatch_penalty = 0.25
                    penalty += first_word_mismatch_penalty
                    if verbose:
                        logger.debug(f"  ‚ö†Ô∏è First word not in top-3, BUT full coverage (-0.25)")
                else:
                    first_word_mismatch_penalty = 0.45
                    penalty += first_word_mismatch_penalty
                    if verbose:
                        logger.debug(f"  ‚ùå CRITICAL: First word not in top-3 AND incomplete (-0.45)")
            else:
                coverage_ratio = (exact_matches + fuzzy_matches) / total_search_words
                if coverage_ratio >= 0.9:
                    first_word_mismatch_penalty = 0.15
                    if verbose:
                        logger.debug(f"  ‚ö†Ô∏è First word at pos {top3_position+1} but high coverage (-0.15)")
                else:
                    first_word_mismatch_penalty = 0.25
                    if verbose:
                        logger.debug(f"  ‚ö†Ô∏è First word at pos {top3_position+1} with low coverage (-0.25)")
                penalty += first_word_mismatch_penalty
        else:
            if first_word_similarity >= 0.95:
                bonus += 0.2
                if verbose:
                    logger.debug(f"  ‚úÖ First word high similarity: +0.2")
            elif first_word_similarity >= 0.7:
                bonus += 0.1
                if verbose:
                    logger.debug(f"  ‚úÖ First word medium similarity: +0.1")
    
    # –®–¢–†–ê–§ –ó–ê –ù–ï–ó–ê–ü–†–û–®–ï–ù–ù–£–Æ –û–ë–†–ê–ë–û–¢–ö–£ –ü–†–û–î–£–ö–¢–ê (v5.3)
    search_modifiers = detect_processing_modifiers(normalized_search_query)
    found_modifiers = detect_processing_modifiers(normalized_found_name)
    
    # –ú–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã, –∫–æ—Ç–æ—Ä—ã–µ –µ—Å—Ç—å –≤ –Ω–∞–π–¥–µ–Ω–Ω–æ–º, –Ω–æ –ù–ï–¢ –≤ –∑–∞–ø—Ä–æ—Å–µ
    unrequested_modifiers = found_modifiers - search_modifiers
    
    if unrequested_modifiers:
        # –ï—Å—Ç—å –Ω–µ–∑–∞–ø—Ä–æ—à–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
        processing_penalty = 0.40  # –°–∏–ª—å–Ω—ã–π —à—Ç—Ä–∞—Ñ
        penalty += processing_penalty
        if verbose:
            logger.debug(f"  ‚ùå Unrequested processing: {unrequested_modifiers} (-{processing_penalty:.2f})")
    
    # –ë–æ–Ω—É—Å—ã –¥–∞—é—Ç—Å—è –ø—Ä–∏ penalty < 0.5
    if total_search_words <= 2 and has_full_coverage:
        if penalty < 0.5:
            full_coverage_bonus = 0.15
            bonus += full_coverage_bonus
            if verbose:
                logger.debug(f"  ‚úÖ Full coverage bonus: +{full_coverage_bonus:.2f}")
    
    exact_ratio = exact_matches / total_search_words
    if exact_ratio >= 0.5:
        if penalty < 0.5:
            exact_match_bonus = exact_ratio * 0.1
            bonus += exact_match_bonus
            if verbose:
                logger.debug(f"  ‚úÖ Exact ratio bonus: +{exact_match_bonus:.2f}")
    
    # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ –ø—Ä–∏ penalty < 0.3
    if has_full_coverage and penalty < 0.3:
        min_score_for_full_coverage = 0.7
        if (base_score + bonus - penalty) < min_score_for_full_coverage:
            coverage_adjustment = min_score_for_full_coverage - (base_score + bonus - penalty)
            bonus += coverage_adjustment
            if verbose:
                logger.debug(f"  ‚úÖ Coverage floor: +{coverage_adjustment:.2f}")
    
    final_score = base_score + bonus - penalty
    final_score = max(0.0, min(1.0, final_score))
    final_score = round(final_score, 3)
    
    is_exact = (exact_matches >= total_search_words or 
               (final_score >= 0.95 and exact_matches + fuzzy_matches >= total_search_words))
    
    if verbose:
        logger.debug(f"  üìä base={base_score:.3f} + bonus={bonus:.3f} - penalty={penalty:.3f} = {final_score:.3f}")
    
    return final_score, is_exact

# ============= –û–°–ù–û–í–ù–ê–Ø –õ–û–ì–ò–ö–ê –†–ï–ú–≠–¢–ß–ò–ù–ì–ê =============

async def rematch_all_stocks(order_id: int = None, dry_run: bool = False, verbose: bool = False):
    """
    –ü–µ—Ä–µ—Å—á–µ—Ç match_score –¥–ª—è –≤—Å–µ—Ö –∑–∞–ø–∏—Å–µ–π lsd_stocks
    
    Args:
        order_id: –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ - –ø–µ—Ä–µ—Å—á–∏—Ç–∞—Ç—å —Ç–æ–ª—å–∫–æ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∑–∞–∫–∞–∑–∞
        dry_run: –ï—Å–ª–∏ True - —Ç–æ–ª—å–∫–æ –ø–æ–∫–∞–∑–∞—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è, –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –≤ –ë–î
        verbose: –ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥ –¥–ª—è –∫–∞–∂–¥–æ–π –∑–∞–ø–∏—Å–∏
    """
    logger.info("=" * 80)
    logger.info("üîÑ REMATCH UTILITY v5.3 - –ü–µ—Ä–µ—Å—á–µ—Ç match_score –¥–ª—è lsd_stocks")
    logger.info("=" * 80)
    
    if dry_run:
        logger.info("üß™ DRY RUN MODE - –∏–∑–º–µ–Ω–µ–Ω–∏—è –ù–ï –±—É–¥—É—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ë–î")
    
    if order_id:
        logger.info(f"üéØ –§–∏–ª—å—Ç—Ä: —Ç–æ–ª—å–∫–æ order_id={order_id}")
    
    logger.info("")
    
    try:
        async for db in get_async_session():
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∑–∞–ø–∏—Å–∏ lsd_stocks —Å –∏—Ö –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º–∏ –∑–∞–ø—Ä–æ—Å–∞–º–∏
            query = select(LSDStock, OrderItem.product_name).join(
                OrderItem, LSDStock.order_item_id == OrderItem.id
            )
            
            if order_id:
                query = query.where(LSDStock.order_id == order_id)
            
            result = await db.execute(query)
            stocks_with_names = result.all()
            
            if not stocks_with_names:
                logger.warning("‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
                return
            
            total_records = len(stocks_with_names)
            logger.info(f"üì¶ –ù–∞–π–¥–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {total_records}")
            logger.info("")
            
            updated_count = 0
            no_change_count = 0
            significant_changes = []
            
            for i, (stock, product_name) in enumerate(stocks_with_names, 1):
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º search_query –µ—Å–ª–∏ –µ—Å—Ç—å, –∏–Ω–∞—á–µ product_name
                search_query = stock.search_query or product_name
                found_name = stock.found_name
                
                # –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º match_score
                new_score, new_is_exact = calculate_match_score_v53(
                    search_query=search_query,
                    found_name=found_name,
                    verbose=verbose
                )
                
                old_score = float(stock.match_score) if stock.match_score else 0.0
                score_diff = new_score - old_score
                
                # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
                if i % 10 == 0 or verbose:
                    logger.info(f"[{i}/{total_records}] –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ...")
                
                # –ï—Å–ª–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–µ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ (>0.1), –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –¥–µ—Ç–∞–ª–∏
                if abs(score_diff) > 0.1:
                    significant_changes.append({
                        'stock_id': stock.id,
                        'search': search_query,
                        'found': found_name,
                        'old_score': old_score,
                        'new_score': new_score,
                        'diff': score_diff
                    })
                    
                    if verbose:
                        logger.info(f"\nüìù –ó–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ:")
                        logger.info(f"  ID: {stock.id}")
                        logger.info(f"  –ó–∞–ø—Ä–æ—Å: '{search_query}'")
                        logger.info(f"  –ù–∞–π–¥–µ–Ω–æ: '{found_name}'")
                        logger.info(f"  –ë—ã–ª–æ: {old_score:.3f} ‚Üí –°—Ç–∞–ª–æ: {new_score:.3f} (Œî {score_diff:+.3f})")
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –≤ –ë–î (–µ—Å–ª–∏ –Ω–µ dry_run)
                if not dry_run:
                    if abs(score_diff) > 0.001:  # –û–±–Ω–æ–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏–µ
                        await db.execute(
                            update(LSDStock)
                            .where(LSDStock.id == stock.id)
                            .values(
                                match_score=Decimal(str(new_score)),
                                is_exact_match=new_is_exact
                            )
                        )
                        updated_count += 1
                    else:
                        no_change_count += 1
                else:
                    if abs(score_diff) > 0.001:
                        updated_count += 1
                    else:
                        no_change_count += 1
            
            if not dry_run:
                await db.commit()
                logger.info("\n‚úÖ –ò–∑–º–µ–Ω–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ë–î")
            
            # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            logger.info("")
            logger.info("=" * 80)
            logger.info("üìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
            logger.info("=" * 80)
            logger.info(f"–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {total_records}")
            logger.info(f"–û–±–Ω–æ–≤–ª–µ–Ω–æ (–∏–∑–º–µ–Ω–µ–Ω–∏–µ score): {updated_count}")
            logger.info(f"–ë–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π: {no_change_count}")
            logger.info(f"–ó–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π (|Œî| > 0.1): {len(significant_changes)}")
            
            if significant_changes:
                logger.info("")
                logger.info("üîç –¢–û–ü-10 –ó–ù–ê–ß–ò–¢–ï–õ–¨–ù–´–• –ò–ó–ú–ï–ù–ï–ù–ò–ô:")
                logger.info("-" * 80)
                
                # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∞–±—Å–æ–ª—é—Ç–Ω–æ–º—É –∏–∑–º–µ–Ω–µ–Ω–∏—é
                significant_changes.sort(key=lambda x: abs(x['diff']), reverse=True)
                
                for change in significant_changes[:10]:
                    logger.info(f"\nID {change['stock_id']}:")
                    logger.info(f"  '{change['search'][:50]}...' vs '{change['found'][:50]}...'")
                    logger.info(f"  {change['old_score']:.3f} ‚Üí {change['new_score']:.3f} ({change['diff']:+.3f})")
            
            logger.info("")
            logger.info("=" * 80)
            logger.info("‚úÖ Rematch completed successfully!")
            logger.info("=" * 80)
            
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ rematch: {e}")
        import traceback
        logger.error(traceback.format_exc())
        raise

async def show_stats(order_id: int = None):
    """–ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ match_score –≤ –ë–î"""
    logger.info("=" * 80)
    logger.info("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê MATCH_SCORE")
    logger.info("=" * 80)
    
    try:
        async for db in get_async_session():
            query = select(LSDStock)
            
            if order_id:
                query = query.where(LSDStock.order_id == order_id)
            
            result = await db.execute(query)
            stocks = result.scalars().all()
            
            if not stocks:
                logger.info("‚ö†Ô∏è –ù–µ—Ç –∑–∞–ø–∏—Å–µ–π –≤ lsd_stocks")
                return
            
            total = len(stocks)
            scores = [float(s.match_score) if s.match_score else 0.0 for s in stocks]
            
            logger.info(f"\n–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {total}")
            logger.info(f"–°—Ä–µ–¥–Ω–∏–π score: {sum(scores)/len(scores):.3f}")
            logger.info(f"–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π: {min(scores):.3f}")
            logger.info(f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π: {max(scores):.3f}")
            
            # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞–º
            ranges = {
                '0.0-0.3': sum(1 for s in scores if s < 0.3),
                '0.3-0.5': sum(1 for s in scores if 0.3 <= s < 0.5),
                '0.5-0.7': sum(1 for s in scores if 0.5 <= s < 0.7),
                '0.7-0.9': sum(1 for s in scores if 0.7 <= s < 0.9),
                '0.9-1.0': sum(1 for s in scores if 0.9 <= s <= 1.0)
            }
            
            logger.info("\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞–º:")
            for range_name, count in ranges.items():
                pct = (count / total * 100) if total > 0 else 0
                logger.info(f"  {range_name}: {count} ({pct:.1f}%)")
            
            logger.info("")
            logger.info("=" * 80)
            
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
        raise

# ============= CLI INTERFACE =============

async def main():
    import argparse
    
    parser = argparse.ArgumentParser(
        description='–£—Ç–∏–ª–∏—Ç–∞ –¥–ª—è –ø–µ—Ä–µ—Å—á–µ—Ç–∞ match_score –≤ lsd_stocks (v5.3 —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏)',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:

  # –ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
  python rematch_stocks.py --stats

  # –ü–µ—Ä–µ—Å—á–∏—Ç–∞—Ç—å –≤—Å–µ –∑–∞–ø–∏—Å–∏ (—Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º)
  python rematch_stocks.py

  # –ü–µ—Ä–µ—Å—á–∏—Ç–∞—Ç—å —Ç–æ–ª—å–∫–æ –¥–ª—è –∑–∞–∫–∞–∑–∞ #123
  python rematch_stocks.py --order-id 123

  # Dry run (–±–µ–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –ë–î)
  python rematch_stocks.py --dry-run

  # –ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥
  python rematch_stocks.py --verbose

  # Dry run + verbose –¥–ª—è –∑–∞–∫–∞–∑–∞ #123
  python rematch_stocks.py --order-id 123 --dry-run --verbose
        """
    )
    
    parser.add_argument('--order-id', type=int, help='–ü–µ—Ä–µ—Å—á–∏—Ç–∞—Ç—å —Ç–æ–ª—å–∫–æ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∑–∞–∫–∞–∑–∞')
    parser.add_argument('--dry-run', action='store_true', help='–ü–æ–∫–∞–∑–∞—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è –±–µ–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –ë–î')
    parser.add_argument('--verbose', '-v', action='store_true', help='–ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥')
    parser.add_argument('--stats', action='store_true', help='–ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É match_score')
    
    args = parser.parse_args()
    
    if args.stats:
        await show_stats(order_id=args.order_id)
    else:
        await rematch_all_stocks(
            order_id=args.order_id,
            dry_run=args.dry_run,
            verbose=args.verbose
        )

if __name__ == "__main__":
    asyncio.run(main())
