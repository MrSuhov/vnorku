"""
–ü–∞—Ä—Å–µ—Ä –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤ (—á–µ—Ä–µ–∑ —Å–ª–µ—à)
–° –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏—è –ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ —Ä–æ–¥—É
"""
import re
from typing import List, Dict, Optional

try:
    from shared.utils.gender_agreement import apply_gender_agreement, get_product_gender
except ImportError:
    # –ó–∞–≥–ª—É—à–∫–∞ –µ—Å–ª–∏ –º–æ–¥—É–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
    def apply_gender_agreement(product_name: str, common_suffix: str, source_gender=None) -> str:
        return common_suffix
    
    def get_product_gender(product_name: str) -> str:
        return 'unknown'


def parse_alternatives(product_text: str) -> Dict[str, any]:
    """
    –ü–∞—Ä—Å–∏—Ç —Å—Ç—Ä–æ–∫—É —Ç–æ–≤–∞—Ä–∞ –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤ (—Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å /)
    –° –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏–µ–º –ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ —Ä–æ–¥—É
    
    –ü—Ä–∏–º–µ—Ä—ã:
        "—Ñ–æ—Ä–µ–ª—å / —Å–µ–º–≥–∞ 500–≥" -> {
            "main": "—Ñ–æ—Ä–µ–ª—å 500–≥",
            "alternatives": ["—Å–µ–º–≥–∞ 500–≥"],
            "has_alternatives": True
        }
        
        "—Ñ–æ—Ä–µ–ª—å / —Å–µ–º–≥–∞ / –ª–æ—Å–æ—Å—å —Å–ª–∞–±–æ—Å–æ–ª–µ–Ω–∞—è —Ä—É—Å—Å–∫–æ–µ –º–æ—Ä–µ" -> {
            "main": "—Ñ–æ—Ä–µ–ª—å —Å–ª–∞–±–æ—Å–æ–ª–µ–Ω–∞—è —Ä—É—Å—Å–∫–æ–µ –º–æ—Ä–µ",
            "alternatives": [
                "—Å–µ–º–≥–∞ —Å–ª–∞–±–æ—Å–æ–ª–µ–Ω–∞—è —Ä—É—Å—Å–∫–æ–µ –º–æ—Ä–µ",  # –∂.—Ä., –Ω–µ –º–µ–Ω—è–µ—Ç—Å—è
                "–ª–æ—Å–æ—Å—å —Å–ª–∞–±–æ—Å–æ–ª–µ–Ω—ã–π —Ä—É—Å—Å–∫–æ–µ –º–æ—Ä–µ"  # –º.—Ä., —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–æ!
            ],
            "has_alternatives": True
        }
    
    Args:
        product_text: –°—Ç—Ä–æ–∫–∞ —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º —Ç–æ–≤–∞—Ä–∞
        
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
    """
    if not product_text or not product_text.strip():
        return {
            "main": "",
            "alternatives": [],
            "has_alternatives": False,
            "full_text": product_text
        }
    
    text = product_text.strip()
    
    # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ —á–∞—Å—Ç–∏ –ø–æ —Å–ª–µ—à—É
    parts = [part.strip() for part in text.split('/')]
    
    if len(parts) == 1:
        # –ù–µ—Ç –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤
        return {
            "main": text,
            "alternatives": [],
            "has_alternatives": False,
            "full_text": text
        }
    
    # –ï—Å—Ç—å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–±—â–∏–µ —Å–ª–æ–≤–∞ (—Å—É—Ñ—Ñ–∏–∫—Å)
    last_part = parts[-1].strip()
    last_part_words = last_part.split()
    
    common_suffix = ""
    alternatives_only = parts.copy()
    
    if len(last_part_words) > 1:
        first_word_of_last = last_part_words[0]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —ç—Ç–æ —Å–ª–æ–≤–æ –≤ –¥—Ä—É–≥–∏—Ö —á–∞—Å—Ç—è—Ö
        found_in_others = False
        for part in parts[:-1]:
            if first_word_of_last.lower() in part.lower():
                found_in_others = True
                break
        
        # –ï—Å–ª–∏ –ø–µ—Ä–≤–æ–µ —Å–ª–æ–≤–æ –ø–æ—Å–ª–µ–¥–Ω–µ–π —á–∞—Å—Ç–∏ –ù–ï –Ω–∞–π–¥–µ–Ω–æ –≤ –¥—Ä—É–≥–∏—Ö,
        # –∑–Ω–∞—á–∏—Ç –≤—Å—ë –ø–æ—Å–ª–µ –ø–µ—Ä–≤–æ–≥–æ —Å–ª–æ–≤–∞ - –æ–±—â–∏–µ —Å–ª–æ–≤–∞
        if not found_in_others:
            alternatives_only[-1] = first_word_of_last
            common_suffix = ' '.join(last_part_words[1:])
    
    # –ù–û–í–û–ï: –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–æ–≤–∞—Ä –∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã –° –°–û–ì–õ–ê–°–û–í–ê–ù–ò–ï–ú –ü–û –†–û–î–£
    main_product_name = alternatives_only[0].strip()
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–æ–¥ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –ø—Ä–æ–¥—É–∫—Ç–∞ (–¥–ª—è –æ—Ç–ª–∞–¥–∫–∏)
    main_gender = get_product_gender(main_product_name)
    
    # –û—Å–Ω–æ–≤–Ω–æ–π —Ç–æ–≤–∞—Ä - –ø—Ä–æ—Å—Ç–æ –¥–æ–±–∞–≤–ª—è–µ–º —Å—É—Ñ—Ñ–∏–∫—Å
    if common_suffix:
        main_product = f"{main_product_name} {common_suffix}"
    else:
        main_product = main_product_name
    
    # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã - —Å–æ–≥–ª–∞—Å—É–µ–º –ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Å —Ä–æ–¥–æ–º –∫–∞–∂–¥–æ–≥–æ –ø—Ä–æ–¥—É–∫—Ç–∞
    alternatives = []
    for alt in alternatives_only[1:]:
        alt_clean = alt.strip()
        if alt_clean:
            if common_suffix:
                # –ö–õ–Æ–ß–ï–í–û–ô –ú–û–ú–ï–ù–¢: —Å–æ–≥–ª–∞—Å—É–µ–º —Å—É—Ñ—Ñ–∏–∫—Å —Å —Ä–æ–¥–æ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã
                agreed_suffix = apply_gender_agreement(alt_clean, common_suffix, main_gender)
                alternatives.append(f"{alt_clean} {agreed_suffix}")
            else:
                alternatives.append(alt_clean)
    
    return {
        "main": main_product,
        "alternatives": alternatives,
        "has_alternatives": len(alternatives) > 0,
        "full_text": text,
        "all_options": [main_product] + alternatives,
        "common_suffix": common_suffix,  # –î–ª—è –æ—Ç–ª–∞–¥–∫–∏
        "main_gender": main_gender  # –î–ª—è –æ—Ç–ª–∞–¥–∫–∏
    }


def extract_product_name_from_alternative(alternative_text: str, quantity_unit: str = None) -> str:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç —á–∏—Å—Ç–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ –∏–∑ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã, —É–¥–∞–ª—è—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏ –µ–¥–∏–Ω–∏—Ü—ã
    
    Args:
        alternative_text: –¢–µ–∫—Å—Ç –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã (–º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ)
        quantity_unit: –ò–∑–≤–µ—Å—Ç–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å –µ–¥–∏–Ω–∏—Ü–µ–π ("500–≥", "1–∫–≥"), –µ—Å–ª–∏ –µ—Å—Ç—å
        
    Returns:
        –ß–∏—Å—Ç–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞
    """
    if quantity_unit:
        text = alternative_text.replace(quantity_unit, '').strip()
    else:
        text = alternative_text.strip()
    
    # –£–¥–∞–ª—è–µ–º —Ç–∏–ø–∏—á–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞
    text = re.sub(r'\d+[\.,]?\d*\s*(–≥|–∫–≥|–ª|–º–ª|—à—Ç|—É–ø–∞–∫)', '', text, flags=re.IGNORECASE)
    text = re.sub(r'\s+', ' ', text).strip()
    
    return text


def normalize_alternatives_for_search(alternatives_data: Dict) -> List[str]:
    """
    –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —Å–ø–∏—Å–æ–∫ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —á–∏—Å—Ç—ã—Ö –Ω–∞–∑–≤–∞–Ω–∏–π —Ç–æ–≤–∞—Ä–æ–≤ –±–µ–∑ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞
    
    Args:
        alternatives_data: –†–µ–∑—É–ª—å—Ç–∞—Ç parse_alternatives()
        
    Returns:
        –°–ø–∏—Å–æ–∫ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –Ω–∞–∑–≤–∞–Ω–∏–π –¥–ª—è –ø–æ–∏—Å–∫–∞
    """
    if not alternatives_data["has_alternatives"]:
        return [alternatives_data["main"]]
    
    search_names = []
    main = alternatives_data["main"]
    
    # –ù–∞—Ö–æ–¥–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º —Ç–æ–≤–∞—Ä–µ
    quantity_match = re.search(r'\d+[\.,]?\d*\s*(–≥|–∫–≥|–ª|–º–ª|—à—Ç|—É–ø–∞–∫)', main, flags=re.IGNORECASE)
    quantity_unit = quantity_match.group(0) if quantity_match else None
    
    # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–æ–≤–∞—Ä (–æ—á–∏—â–µ–Ω–Ω—ã–π)
    main_clean = extract_product_name_from_alternative(main, quantity_unit)
    if main_clean:
        search_names.append(main_clean)
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã (–æ—á–∏—â–µ–Ω–Ω—ã–µ)
    for alt in alternatives_data["alternatives"]:
        alt_clean = extract_product_name_from_alternative(alt, quantity_unit)
        if alt_clean and alt_clean not in search_names:
            search_names.append(alt_clean)
    
    return search_names


def test_alternatives_parser():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞—Ä—Å–µ—Ä–∞ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤ —Å —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏–µ–º –ø–æ —Ä–æ–¥—É"""
    test_cases = [
        # –¢–µ—Å—Ç 1: –ü—Ä–æ—Å—Ç—ã–µ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã –±–µ–∑ –æ–±—â–∏—Ö —Å–ª–æ–≤
        {
            "input": "—Ñ–æ—Ä–µ–ª—å / —Å–µ–º–≥–∞ 500–≥",
            "expected_main": "—Ñ–æ—Ä–µ–ª—å 500–≥",
            "expected_alternatives": ["—Å–µ–º–≥–∞ 500–≥"]
        },
        
        # –¢–µ—Å—Ç 2: –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã —Å —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–∏–µ–º (–∫–ª—é—á–µ–≤–æ–π —Ç–µ—Å—Ç!)
        {
            "input": "—Ñ–æ—Ä–µ–ª—å / —Å–µ–º–≥–∞ / –ª–æ—Å–æ—Å—å —Å–ª–∞–±–æ—Å–æ–ª–µ–Ω–∞—è —Ä—É—Å—Å–∫–æ–µ –º–æ—Ä–µ",
            "expected_main": "—Ñ–æ—Ä–µ–ª—å —Å–ª–∞–±–æ—Å–æ–ª–µ–Ω–∞—è —Ä—É—Å—Å–∫–æ–µ –º–æ—Ä–µ",
            "expected_alternatives": [
                "—Å–µ–º–≥–∞ —Å–ª–∞–±–æ—Å–æ–ª–µ–Ω–∞—è —Ä—É—Å—Å–∫–æ–µ –º–æ—Ä–µ",  # –∂.—Ä., –Ω–µ –º–µ–Ω—è–µ—Ç—Å—è
                "–ª–æ—Å–æ—Å—å —Å–ª–∞–±–æ—Å–æ–ª–µ–Ω—ã–π —Ä—É—Å—Å–∫–æ–µ –º–æ—Ä–µ"  # –º.—Ä., –î–û–õ–ñ–ù–û –ò–ó–ú–ï–ù–ò–¢–¨–°–Ø!
            ]
        },
        
        # –¢–µ—Å—Ç 3: –°—Ä–µ–¥–Ω–∏–π —Ä–æ–¥ -> –º—É–∂—Å–∫–æ–π
        {
            "input": "–º–æ–ª–æ–∫–æ / –∫–µ—Ñ–∏—Ä —Ü–µ–ª—å–Ω–æ–µ 3.2%",
            "expected_main": "–º–æ–ª–æ–∫–æ —Ü–µ–ª—å–Ω–æ–µ 3.2%",
            "expected_alternatives": ["–∫–µ—Ñ–∏—Ä —Ü–µ–ª—å–Ω—ã–π 3.2%"]
        },
        
        # –¢–µ—Å—Ç 4: –ë–µ–∑ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤
        {
            "input": "–º–æ–ª–æ–∫–æ 3.2% 1–ª",
            "expected_main": "–º–æ–ª–æ–∫–æ 3.2% 1–ª",
            "expected_alternatives": []
        },
    ]
    
    print("üß™ Testing alternatives parser with gender agreement:")
    print("=" * 80)
    
    all_passed = True
    
    for i, test in enumerate(test_cases, 1):
        parsed = parse_alternatives(test["input"])
        
        main_match = parsed["main"] == test["expected_main"]
        alt_match = parsed["alternatives"] == test["expected_alternatives"]
        
        passed = main_match and alt_match
        all_passed = all_passed and passed
        
        status = "‚úÖ PASS" if passed else "‚ùå FAIL"
        
        print(f"\nTest {i}: {status}")
        print(f"  Input: '{test['input']}'")
        print(f"  Main: '{parsed['main']}'")
        if not main_match:
            print(f"    ‚ùå Expected: '{test['expected_main']}'")
        print(f"  Alternatives: {parsed['alternatives']}")
        if not alt_match:
            print(f"    ‚ùå Expected: {test['expected_alternatives']}")
        
        if 'main_gender' in parsed:
            print(f"  Main gender: {parsed['main_gender']}")
    
    print("\n" + "=" * 80)
    if all_passed:
        print("‚úÖ All tests PASSED!")
    else:
        print("‚ùå Some tests FAILED")
    print("=" * 80)


if __name__ == "__main__":
    test_alternatives_parser()
